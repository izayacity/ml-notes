{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "220dfb6c-0b65-40cb-ad65-8d3ac2e570b3",
   "metadata": {},
   "source": [
    "## Multiclass classification\n",
    "\n",
    "In the previous chapters we focused on binary classification, labeling whether or not an input data point has some class attribute (e.g. if it is in a circle or not). Now, we will attempt to classify input data points when there are multiple possible classes and the data point belongs to exactly one. This is referred to as multiclass classification.\n",
    "\n",
    "The example is an extension of the previous circle example, but now there is an additional circle with radius 1 centered at the origin. The classes are now:\n",
    "- 0: Outside both circles\n",
    "- 1: Inside the smaller circle\n",
    "- 2: Outside the smaller circle but inside the larger circle\n",
    "\n",
    "## One-hot\n",
    "\n",
    "Instead of representing each label as a single number, we use a one-hot vector. A one-hot vector has length equal to the number of classes, which is the same as output_size. The vector contains a single 1 at the index of the class that the data point belongs to, i.e. the hot index, and 0's at the other indexes. The labels now become a set of one-hot vectors for each data point:\n",
    "\n",
    "![title](img/one_hot.png)\n",
    "\n",
    "An example set of labels. In this case there are 3 possible classes, exactly one of which is the hot index.\n",
    "\n",
    "Another way to think about one-hot vectors is as multiple binary classification. The actual class of the data point is labeled as 1 (True), while the other classes are labeled as 0 (False).\n",
    "\n",
    "## Adding hidden layers\n",
    "\n",
    "Since there are now multiple decision boundaries, it would be beneficial to either increase the size of our model's current hidden layer, hidden1, or add another hidden layer. Given that the decision boundaries are still relatively trivial, both methods would lead to successful models eventually. However, adding an extra hidden layer may decrease the number of training iterations needed for convergence compared to maintaining a single hidden layer.\n",
    "\n",
    "When deciding how many hidden layers a model needs (i.e. how deep it is) and how many neurons are at each hidden layer, it is a good idea to base the decision on the problem itself. There are a few general rules of thumb, but they do not apply to every scenario.\n",
    "- For example, it is common not to need more than 3 hidden layers in a neural network, but if you are working on a complicated problem you would most likely need more (Google's Alpha Go needed more than a dozen layers).\n",
    "- If you don't have much domain knowledge for the particular problem you're working on, it's usually best to only add extra layers or neurons when they're needed.\n",
    "- The fewer layers and neurons, the faster your model trains, and the quicker you can evaluate how good it is. It then becomes easier to optimize the number of layers and neurons in your model through experimentation.\n",
    "\n",
    "## Overfitting\n",
    "\n",
    "One thing to note is that the more hidden layers or neurons a neural network has, the more prone it is to overfitting the training data. Overfitting refers to the model becoming very accurate in classifying the training data, but then performing poorly on other data. Since we want models that can generalize well and accurately classify data it has never seen before, it is best to avoid going overboard in adding hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca5a554-c29d-4414-8621-88dba987c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(inputs, output_size):\n",
    "  hidden1_inputs = inputs\n",
    "  hidden1 = tf.keras.layers.Dense(units=5,\n",
    "                            activation=tf.nn.relu,\n",
    "                            name='hidden1')(hidden1_inputs)\n",
    "\n",
    "  hidden2_inputs = hidden1\n",
    "  hidden2 = tf.keras.layers.Dense(units=5,\n",
    "                            activation=tf.nn.relu,\n",
    "                            name='hidden2')(hidden2_inputs)\n",
    "\n",
    "  logits_inputs = hidden2\n",
    "  logits = tf.keras.layers.Dense(units=output_size,\n",
    "                           name='logits')(logits_inputs)\n",
    "  return hidden1_inputs, hidden1, hidden2_inputs, hidden2, logits_inputs, logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
