{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1655528-6192-4ea1-9df7-f07b8defa8b8",
   "metadata": {},
   "source": [
    "## The softmax function\n",
    "\n",
    "To convert the model to multiclass classification, we need to make a few changes to the metrics and training parameters. Previously, we used the sigmoid function to convert logits to probabilities, then rounded those probabilities to get a predicted label. However, now that there are multiple possible classes, we need to use the generalization of the sigmoid function, known as the softmax function.\n",
    "\n",
    "The softmax function takes in a vector of numbers (logits for each class), and converts the numbers to a probability distribution. This means that the sum of the probabilities across all the classes equals 1, and each class's individual probability is based on how large its logit was relative to the sum of all the classes's logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a36ce463-6de7-4ecb-bd5a-bec8abe7bdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 0.4, -0.8,  1.3],\n",
      "       [ 0.2, -1.2, -0.4]], dtype=float32)\n",
      "\n",
      "array([[0.2659011 , 0.08008787, 0.65401113],\n",
      "       [0.5569763 , 0.13734867, 0.30567506]], dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    t = tf.constant([[0.4, -0.8, 1.3],\n",
    "                 [0.2, -1.2, -0.4]])\n",
    "    softmax_t = tf.nn.softmax(t)\n",
    "\n",
    "    print('{}\\n'.format(repr(sess.run(t))))\n",
    "    print('{}\\n'.format(repr(sess.run(softmax_t))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad2d484-4f05-4b7e-8dc9-4c005deaa26a",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "Our model's prediction now becomes the class with the highest probability. Since we label each class with a unique index, we need to return the index with the maximum probability. TensorFlow provides a function that lets us do this, called tf.math.argmax.\n",
    "\n",
    "The function takes in a required input tensor, as well as a few keyword arguments. One of the more important keyword arguments is axis, which tells us which dimension to retrieve the maximum index from. Setting axis=-1 uses the final dimension, which in this case corresponds to retrieving the column index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3b32b76-35ca-43e3-b333-8b5fcf70f402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.4, 0.3, 0.3],\n",
      "       [0.2, 0.7, 0.1]], dtype=float32)\n",
      "\n",
      "array([0, 1], dtype=int64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    probs = tf.constant([[0.4, 0.3, 0.3],\n",
    "                     [0.2, 0.7, 0.1]])\n",
    "    preds = tf.argmax(probs, axis=-1)\n",
    "\n",
    "    print('{}\\n'.format(repr(sess.run(probs))))\n",
    "    print('{}\\n'.format(repr(sess.run(preds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a2bf03-ac5c-49bc-9146-f4d6f9f04ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
