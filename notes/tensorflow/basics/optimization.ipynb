{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6764699-6ad5-436d-ae4e-09f0fd55058d",
   "metadata": {},
   "source": [
    "## What is training\n",
    "\n",
    "In Chapter 3, we discussed the weights associated with connections between neurons. These weights determine what a neural network outputs based on the input data. However, these weights are what we call trainable variables, meaning that we need to train our neural network to find the optimal weights for each connection.\n",
    "\n",
    "For any neural network, training involves setting up a loss function. The loss function tells us how bad the neural network's output is compared to the actual labels.\n",
    "\n",
    "Since a larger loss means a worse model, we want to train the model to output values that minimize the loss function. The model does this by learning the optimal weight settings. Remember, the weights are just real numbers, so the model is essentially just figuring out the best numbers to set the weights to.\n",
    "\n",
    "## Loss as error\n",
    "\n",
    "In regression problems, common loss functions are the L1 norm:\n",
    "\n",
    "​i\n",
    "​∑\n",
    "​​ ∣actual_i\n",
    "​​ − predicted_i\n",
    "​​ ∣\n",
    "\n",
    "and the L2 norm:\n",
    "\n",
    "​i\n",
    "​∑\n",
    "​​ (actual_i\n",
    "​​ − predicted_i\n",
    "​​ )\n",
    "​^2\n",
    "​​\n",
    "\n",
    "These provide an error metric for how far the predictions are from the labels, so the goal is to minimize the prediction error by minimizing the L1 and L2 norm. In classification problems there's no good error measurement between predictions and labels, since the labels are discrete values.\n",
    "- In regression if we predict a stock's price was \\\\$99 but the actual value was \\\\$100, our prediction is still really good even though it was incorrect.\n",
    "- However, in classification a prediction is either right or wrong, without any sense of how close it is to the actual label.\n",
    "\n",
    "## Cross entropy\n",
    "\n",
    "Rather than defining error as being right or wrong in our prediction, we can instead define it in terms of probability. Therefore, we want a loss function that is small when the probability is close to the label (i.e. a probability of 0.99 for a label of 1) and large when the probability is far from the label (i.e. a probability of 0.99 for a label of 0). The loss function that achieves this is known as cross entropy(https://en.wikipedia.org/wiki/Cross_entropy), also referred to as log loss.\n",
    "\n",
    "![title](img/cross_entropy.png)\n",
    "\n",
    "Cross entropy (log loss) for a label of 1. Thex-axis represents the probability and the y-axis represents the log loss.\n",
    "\n",
    "## Optimization\n",
    "\n",
    "Now we can just minimize the cross entropy based on the model's logits and labels to get our optimal weights. We do this through gradient descent(https://en.wikipedia.org/wiki/Gradient_descent), where the model updates its weights based on a gradient of the loss function until it reaches the minimum loss (at which point the weights converge to the optimum). We use backpropagation(https://en.wikipedia.org/wiki/Backpropagation) to find the optimal gradient for the model to follow. Gradient descent is implemented as an object in TensorFlow, called tf.compat.v1.train.GradientDescentOptimizer.\n",
    "\n",
    "![title](img/gradient_descent.PNG)\n",
    "\n",
    "In the above graph, the colored shape represents values of the loss function, and the x and y axes represent weight values in the model. The model follows a gradient (red line) towards the minimum of the loss function.\n",
    "\n",
    "The size of the gradient depends on something called the learning rate. A larger learning rate means the model could potentially reach the minimum loss quicker, but could also overshoot the minimum. Smaller learning rates are more likely to reach the minimum, but may take longer. Usually we test out learning rates between 0.001 to 0.1 to find the best one for model training. You can set the learning rate via the learning_rate argument when initializing a TensorFlow Optimizer (e.g. GradientDescentOptimizer).\n",
    "\n",
    "Regular gradient descent has trouble minimizing complex loss functions, so we usually use better optimization methods for training. A popular and effective optimization method is Adam(https://arxiv.org/abs/1412.6980), which is implemented in TensorFlow as tf.compat.v1.train.AdamOptimizer. It has default values already set for its parameters (e.g. learning_rate), so in our code we initialize the object with no arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9abd82b-d37c-499f-ace4-33731aaa3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_float = tf.cast(labels, tf.float32)\n",
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels_float, logits=logits)\n",
    "loss = tf.math.reduce_mean(cross_entropy)\n",
    "\n",
    "adam = tf.compat.v1.train.AdamOptimizer()\n",
    "train_op = adam.minimize(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
