{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5207a2-629c-475d-b2ed-e69caf4690b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f4ba07-92df-44fe-b8b0-529a14db1752",
   "metadata": {},
   "source": [
    "## Placeholder\n",
    "\n",
    "When building the computation graph of our model, tf.compat.v1.placeholder acts as a \"placeholder\" for the input data and labels. Without the tf.compat.v1.placeholder, we would not be able to train our model on real input data.\n",
    "\n",
    "A tf.compat.v1.placeholder takes in a required first argument and two keyword arguments called shape and name.\n",
    "\n",
    "The required argument for the placeholder is its type. In Deep Learning with TensorFlow, our input data is pairs of (x, y) points, so self.inputs has type tf.float32. The labels (which are explained in a later chapter) have type tf.int32.\n",
    "\n",
    "The name keyword argument allows us to give a custom name to our placeholder, making it easier for debugging.\n",
    "\n",
    "## Shapes and dimensions\n",
    "\n",
    "The shape argument is a tuple of integers representing the size of each of the placeholder tensor's dimensions. In Deep Learning with TensorFlow, and many real world problems, the shape of the input data will be a two integer tuple. If we view the input data as coming from a data table, the shape is akin to the dimensions of the table.\n",
    "\n",
    "The first integer represents the number of data points we pass in (i.e. number of rows in the data table). When training the model, we refer to the first dimension as the batch size.\n",
    "\n",
    "The second integer represents the number of features in the dataset (i.e. number of columns). In the remaining chapters of Deep Learning with TensorFlow, our input data will have two features: the x and y coordinates of the data point. So input_size is 2.\n",
    "\n",
    "Each data point also has a label, which is used to identify and categorize the data. The labels we use for our model's data will have a two dimension shape, with output_size as the second dimension (the first dimension is still the batch size). The output_size refers to the number of possible classes a label can have (explained in a later chapter).\n",
    "\n",
    "## Different amounts of data\n",
    "\n",
    "One thing to note about TensorFlow is the use of None in place of a dimension size. When we use None in the shape tuple, we are allowing that dimension to take on any size. This is particularly useful because we will use our neural network on input data with different input sizes.\n",
    "\n",
    "When we input multiple input data for our neural network, we don't actually use multiple neural networks. Rather, we use the same neural network on each of the points simultaneously to obtain the network's output for each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bb0962-603f-43d7-a333-a69eab70c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_inputs(input_size):\n",
    "  inputs = tf.compat.v1.placeholder(\n",
    "    tf.float32, shape=(None, input_size), name='inputs')\n",
    "  return inputs\n",
    "\n",
    "\n",
    "def init_labels(output_size):\n",
    "  labels = tf.compat.v1.placeholder(\n",
    "    tf.int32, shape=(None, output_size), name='labels')\n",
    "  return labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
