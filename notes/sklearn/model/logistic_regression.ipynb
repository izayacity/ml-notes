{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71162fc3-65cd-4050-b2a6-689acff530eb",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "The logistic regression model, despite its name, is actually a linear model for classification. It is called logistic regression because it performs regression on logits(https://en.wikipedia.org/wiki/Logit), which then allows us to classify the data based on model probability predictions.\n",
    "\n",
    "We implement logistic regression with the LogisticRegression object (part of the linear_model module). The default setting for LogisticRegression is binary classification, i.e. classifying data observations that are labeled with either a 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281506cd-4ccb-45ce-9639-065dce96cb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (150, 4)\n",
      "\n",
      "Labels:\n",
      "(150,)\n",
      "\n",
      "Prediction classes: array([0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([\n",
    "   [5.1,3.5,1.4,0.2],\n",
    " [4.9,3., 1.4,0.2],\n",
    " [4.7,3.2,1.3,0.2],\n",
    " [4.6,3.1,1.5,0.2],\n",
    " [5., 3.6,1.4,0.2],\n",
    " [5.4,3.9,1.7,0.4],\n",
    " [4.6,3.4,1.4,0.3],\n",
    " [5., 3.4,1.5,0.2],\n",
    " [4.4,2.9,1.4,0.2],\n",
    " [4.9,3.1,1.5,0.1],\n",
    " [5.4,3.7,1.5,0.2],\n",
    " [4.8,3.4,1.6,0.2],\n",
    " [4.8,3., 1.4,0.1],\n",
    " [4.3,3., 1.1,0.1],\n",
    " [5.8,4., 1.2,0.2],\n",
    " [5.7,4.4,1.5,0.4],\n",
    " [5.4,3.9,1.3,0.4],\n",
    " [5.1,3.5,1.4,0.3],\n",
    " [5.7,3.8,1.7,0.3],\n",
    " [5.1,3.8,1.5,0.3],\n",
    " [5.4,3.4,1.7,0.2],\n",
    " [5.1,3.7,1.5,0.4],\n",
    " [4.6,3.6,1., 0.2],\n",
    " [5.1,3.3,1.7,0.5],\n",
    " [4.8,3.4,1.9,0.2],\n",
    " [5., 3., 1.6,0.2],\n",
    " [5., 3.4,1.6,0.4],\n",
    " [5.2,3.5,1.5,0.2],\n",
    " [5.2,3.4,1.4,0.2],\n",
    " [4.7,3.2,1.6,0.2],\n",
    " [4.8,3.1,1.6,0.2],\n",
    " [5.4,3.4,1.5,0.4],\n",
    " [5.2,4.1,1.5,0.1],\n",
    " [5.5,4.2,1.4,0.2],\n",
    " [4.9,3.1,1.5,0.2],\n",
    " [5., 3.2,1.2,0.2],\n",
    " [5.5,3.5,1.3,0.2],\n",
    " [4.9,3.6,1.4,0.1],\n",
    " [4.4,3., 1.3,0.2],\n",
    " [5.1,3.4,1.5,0.2],\n",
    " [5., 3.5,1.3,0.3],\n",
    " [4.5,2.3,1.3,0.3],\n",
    " [4.4,3.2,1.3,0.2],\n",
    " [5., 3.5,1.6,0.6],\n",
    " [5.1,3.8,1.9,0.4],\n",
    " [4.8,3., 1.4,0.3],\n",
    " [5.1,3.8,1.6,0.2],\n",
    " [4.6,3.2,1.4,0.2],\n",
    " [5.3,3.7,1.5,0.2],\n",
    " [5., 3.3,1.4,0.2],\n",
    " [7., 3.2,4.7,1.4],\n",
    " [6.4,3.2,4.5,1.5],\n",
    " [6.9,3.1,4.9,1.5],\n",
    " [5.5,2.3,4., 1.3],\n",
    " [6.5,2.8,4.6,1.5],\n",
    " [5.7,2.8,4.5,1.3],\n",
    " [6.3,3.3,4.7,1.6],\n",
    " [4.9,2.4,3.3,1. ],\n",
    " [6.6,2.9,4.6,1.3],\n",
    " [5.2,2.7,3.9,1.4],\n",
    " [5., 2., 3.5,1. ],\n",
    " [5.9,3., 4.2,1.5],\n",
    " [6., 2.2,4., 1. ],\n",
    " [6.1,2.9,4.7,1.4],\n",
    " [5.6,2.9,3.6,1.3],\n",
    " [6.7,3.1,4.4,1.4],\n",
    " [5.6,3., 4.5,1.5],\n",
    " [5.8,2.7,4.1,1. ],\n",
    " [6.2,2.2,4.5,1.5],\n",
    " [5.6,2.5,3.9,1.1],\n",
    " [5.9,3.2,4.8,1.8],\n",
    " [6.1,2.8,4., 1.3],\n",
    " [6.3,2.5,4.9,1.5],\n",
    " [6.1,2.8,4.7,1.2],\n",
    " [6.4,2.9,4.3,1.3],\n",
    " [6.6,3., 4.4,1.4],\n",
    " [6.8,2.8,4.8,1.4],\n",
    " [6.7,3., 5., 1.7],\n",
    " [6., 2.9,4.5,1.5],\n",
    " [5.7,2.6,3.5,1. ],\n",
    " [5.5,2.4,3.8,1.1],\n",
    " [5.5,2.4,3.7,1. ],\n",
    " [5.8,2.7,3.9,1.2],\n",
    " [6., 2.7,5.1,1.6],\n",
    " [5.4,3., 4.5,1.5],\n",
    " [6., 3.4,4.5,1.6],\n",
    " [6.7,3.1,4.7,1.5],\n",
    " [6.3,2.3,4.4,1.3],\n",
    " [5.6,3., 4.1,1.3],\n",
    " [5.5,2.5,4., 1.3],\n",
    " [5.5,2.6,4.4,1.2],\n",
    " [6.1,3., 4.6,1.4],\n",
    " [5.8,2.6,4., 1.2],\n",
    " [5., 2.3,3.3,1. ],\n",
    " [5.6,2.7,4.2,1.3],\n",
    " [5.7,3., 4.2,1.2],\n",
    " [5.7,2.9,4.2,1.3],\n",
    " [6.2,2.9,4.3,1.3],\n",
    " [5.1,2.5,3., 1.1],\n",
    " [5.7,2.8,4.1,1.3],\n",
    " [6.3,3.3,6., 2.5],\n",
    " [5.8,2.7,5.1,1.9],\n",
    " [7.1,3., 5.9,2.1],\n",
    " [6.3,2.9,5.6,1.8],\n",
    " [6.5,3., 5.8,2.2],\n",
    " [7.6,3., 6.6,2.1],\n",
    " [4.9,2.5,4.5,1.7],\n",
    " [7.3,2.9,6.3,1.8],\n",
    " [6.7,2.5,5.8,1.8],\n",
    " [7.2,3.6,6.1,2.5],\n",
    " [6.5,3.2,5.1,2. ],\n",
    " [6.4,2.7,5.3,1.9],\n",
    " [6.8,3., 5.5,2.1],\n",
    " [5.7,2.5,5., 2. ],\n",
    " [5.8,2.8,5.1,2.4],\n",
    " [6.4,3.2,5.3,2.3],\n",
    " [6.5,3., 5.5,1.8],\n",
    " [7.7,3.8,6.7,2.2],\n",
    " [7.7,2.6,6.9,2.3],\n",
    " [6., 2.2,5., 1.5],\n",
    " [6.9,3.2,5.7,2.3],\n",
    " [5.6,2.8,4.9,2. ],\n",
    " [7.7,2.8,6.7,2. ],\n",
    " [6.3,2.7,4.9,1.8],\n",
    " [6.7,3.3,5.7,2.1],\n",
    " [7.2,3.2,6., 1.8],\n",
    " [6.2,2.8,4.8,1.8],\n",
    " [6.1,3., 4.9,1.8],\n",
    " [6.4,2.8,5.6,2.1],\n",
    " [7.2,3., 5.8,1.6],\n",
    " [7.4,2.8,6.1,1.9],\n",
    " [7.9,3.8,6.4,2. ],\n",
    " [6.4,2.8,5.6,2.2],\n",
    " [6.3,2.8,5.1,1.5],\n",
    " [6.1,2.6,5.6,1.4],\n",
    " [7.7,3., 6.1,2.3],\n",
    " [6.3,3.4,5.6,2.4],\n",
    " [6.4,3.1,5.5,1.8],\n",
    " [6., 3., 4.8,1.8],\n",
    " [6.9,3.1,5.4,2.1],\n",
    " [6.7,3.1,5.6,2.4],\n",
    " [6.9,3.1,5.1,2.3],\n",
    " [5.8,2.7,5.1,1.9],\n",
    " [6.8,3.2,5.9,2.3],\n",
    " [6.7,3.3,5.7,2.5],\n",
    " [6.7,3., 5.2,2.3],\n",
    " [6.3,2.5,5., 1.9],\n",
    " [6.5,3., 5.2,2. ],\n",
    " [6.2,3.4,5.4,2.3],\n",
    " [5.9,3., 5.1,1.8]\n",
    "])\n",
    "labels = np.array([\n",
    "    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
    "1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,\n",
    "2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,\n",
    "2,2\n",
    "])\n",
    "print('Data shape: {}\\n'.format(data.shape))\n",
    "print('Labels:\\n{}\\n'.format(labels.shape))\n",
    "\n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(data, labels)\n",
    "\n",
    "new_data = np.array([\n",
    "  [  0.3,  0.5, -1.2,  1.4],\n",
    "  [ -1.3,  1.8, -0.6, -8.2]])\n",
    "print('Prediction classes: {}\\n'.format(\n",
    "  repr(reg.predict(new_data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d53e4e6-81da-4ef5-8364-1267817a9fe4",
   "metadata": {},
   "source": [
    "The code above created a logistic regression model from a labeled dataset. The model predicts 1 and 0, respectively, as the labels for the observations in new_data.\n",
    "\n",
    "For multiclass classification, i.e. when there are more than two labels, we initialize the LogisticRegression object with the multi_class keyword argument. The default value is 'ovr', which signifies a One-Vs-Rest strategy(https://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-rest). In multiclass classification, we want to use the 'multinomial' strategy.\n",
    "\n",
    "Note that to use the 'multinomial' strategy, we need to choose a proper solver (see below for details on solvers). In this case, we choose 'lbfgs'. To initialize the LogisticRegression object, we give an additional argument max_iter. If we donâ€™t explicitly pass this argument, It uses the default value which is 100, and It may produce a ConvergenceWarning. To avoid this warning, you can try increasing its value as in this case we used max_iter=200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84f7890d-bf06-4049-995a-a401f889e923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction classes: array([2, 0])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reg = linear_model.LogisticRegression(\n",
    "  solver='lbfgs',\n",
    "  multi_class='multinomial', max_iter=200)\n",
    "reg.fit(data, labels)\n",
    "\n",
    "new_data = np.array([\n",
    "  [ 1.8, -0.5, 6.2, 1.4],\n",
    "  [ 3.3,  0.8, 0.1, 2.5]])\n",
    "print('Prediction classes: {}\\n'.format(\n",
    "  repr(reg.predict(new_data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82489bbd-69f5-4c33-b22d-7c92a4aec476",
   "metadata": {},
   "source": [
    "## Solvers\n",
    "\n",
    "The LogisticRegression object uses a solver to obtain the optimal weight settings based on the input data and labels. The five solvers and their various properties are shown in the table below (which comes from the scikit-learn official website):\n",
    "\n",
    "![title](img/solvers.png)\n",
    "\n",
    "By default, the logistic regression is regularized through the L2 norm of weights. We can manually specify whether to use the L1 or L2 norm with the penalty keyword argument, by setting it as either 'l1' or 'l2'.\n",
    "\n",
    "We can choose a particular solver using the solver keyword argument. The default solver is currently 'liblinear' (although it will change to 'lbfgs' in future version). For the 'newton-cg', 'sag', and 'lbfgs' solvers, we can also set the maximum number of iterations the solver takes until the model's weights converge using the max_iter keyword argument. Since the default max_iter value is 100, we may want to let the solver run for a higher number of iterations in certain applications.\n",
    "\n",
    "## Cross-validated model\n",
    "\n",
    "Like the ridge and LASSO regression models, the logistic regression model comes with a cross-validated version in scikit-learn. The cross-validated logistic regression object, LogisticRegressionCV, is initialized and used in the same way as the regular LogisticRegression object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131c0cb9-ab5c-4d08-8745-576f2623fa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LogisticRegressionCV(\n",
    "  solver='multinomial', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a35745-970a-49dd-b58b-959eb8321705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
