{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "375dec69-7f79-4eb9-8ab4-86ba962664ca",
   "metadata": {},
   "source": [
    "## Standard data format\n",
    "\n",
    "When data can take on any range of values, it makes it difficult to interpret. Therefore, data scientists will convert the data into a standard format to make it easier to understand. The standard format refers to data that has 0 mean and unit variance (i.e. standard deviation = 1), and the process of converting data into this format is called data standardization.\n",
    "\n",
    "For each data value, x, we subtract the overall mean of the data, μ, then divide by the overall standard deviation, σ. The new value, z, represents the standardized data value. Thus, the formula for data standardization is:\n",
    "\n",
    "z = (x − μ) / σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "098d6e9e-29b4-4e18-9e09-a4c3ec4d8933",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp38-cp38-win_amd64.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\franc\\appdata\\roaming\\python\\python38\\site-packages (from scikit-learn->sklearn) (1.22.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting scipy>=1.1.0\n",
      "  Downloading scipy-1.7.3-cp38-cp38-win_amd64.whl (34.2 MB)\n",
      "     -------------------------------------- 34.2/34.2 MB 575.1 kB/s eta 0:00:00\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "     ------------------------------------ 307.0/307.0 KB 758.9 kB/s eta 0:00:00\n",
      "Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "  Running setup.py install for sklearn: started\n",
      "  Running setup.py install for sklearn: finished with status 'done'\n",
      "Successfully installed joblib-1.1.0 scikit-learn-1.0.2 scipy-1.7.3 sklearn-0.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "# !python -m pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66fa3e0-9562-4db7-94c3-1b2b7b8293aa",
   "metadata": {},
   "source": [
    "## NumPy and scikit-learn\n",
    "For most scikit-learn functions, the input data comes in the form of a NumPy array.\n",
    "\n",
    "Note: The array’s rows represent individual data observations, while each column represents a particular feature of the data, i.e. the same format as a spreadsheet data table.\n",
    "\n",
    "The scikit-learn data preprocessing module is called sklearn.preprocessing. One of the functions in this module, scale, applies data standardization to a given axis of a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18174975-3c54-40e8-a359-d48b75c4a0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2100, 10, 800], [2500, 11, 850], [1800, 10, 760], [2000, 12, 800], [2300, 11, 810]]\n",
      "\n",
      "array([[-0.16552118, -1.06904497, -0.1393466 ],\n",
      "       [ 1.4896906 ,  0.26726124,  1.60248593],\n",
      "       [-1.40693001, -1.06904497, -1.53281263],\n",
      "       [-0.57932412,  1.60356745, -0.1393466 ],\n",
      "       [ 0.66208471,  0.26726124,  0.2090199 ]])\n",
      "\n",
      "array([ 0., -0.,  0.])\n",
      "\n",
      "array([1., 1., 1.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "pizza_data = [[2100,   10,  800],\n",
    "       [2500,   11,  850],\n",
    "       [1800,   10,  760],\n",
    "       [2000,   12,  800],\n",
    "       [2300,   11,  810]]\n",
    "print('{}\\n'.format(repr(pizza_data)))\n",
    "\n",
    "# Standardizing each column of pizza_data\n",
    "col_standardized = scale(pizza_data)\n",
    "print('{}\\n'.format(repr(col_standardized)))\n",
    "\n",
    "# Column means (rounded to nearest thousandth)\n",
    "col_means = col_standardized.mean(axis=0).round(decimals=3)\n",
    "print('{}\\n'.format(repr(col_means)))\n",
    "\n",
    "# Column standard deviations\n",
    "col_stds = col_standardized.std(axis=0)\n",
    "print('{}\\n'.format(repr(col_stds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3877ccd6-2fdf-49a5-b24b-fff9ea4dd840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
