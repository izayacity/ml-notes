{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0271b4-4320-43b6-a9cc-627d9aa4b122",
   "metadata": {},
   "source": [
    "## Iterator\n",
    "\n",
    "The previous few chapters focused on creating and configuring datasets. In this chapter, we’ll discuss how to iterate through a dataset and extract the data.\n",
    "\n",
    "To iterate through a dataset, we need to create an Iterator object. There are a few different ways to create an Iterator, but we’ll focus on the simplest and most commonly used method, which is the make_one_shot_iterator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d46244f-447a-4249-9495-fc6855532a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1. 2.]], shape=(1, 2), dtype=float64)\n",
      "tf.Tensor([[2. 3.]], shape=(1, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "data = np.array([[1., 2.],\n",
    "       [3., 4.]])\n",
    "dataset = tf.compat.v1.data.Dataset.from_tensor_slices(data)\n",
    "dataset = dataset.batch(1)\n",
    "\n",
    "it = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "next_elem = it.get_next()\n",
    "print(next_elem)\n",
    "\n",
    "added = next_elem + 1\n",
    "print(added)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5756d1fe-45d8-4321-a8a0-9174ff0ccbdb",
   "metadata": {},
   "source": [
    "In the example, it represents an Iterator for dataset. The get_next function returns something we’ll refer to as the next-element tensor.\n",
    "\n",
    "The next-element tensor represents the batched data observation(s) at each iteration through the dataset. We can even apply operations or transformations to the next-element tensor. In the example above, we added 1 to each of the values in the data observation represented by next_elem.\n",
    "\n",
    "## Running the iteration\n",
    "\n",
    "You’ll notice that the next-element tensor is a tf.Tensor object. We use a tf.compat.v1.Session object to retrieve the values from a tf.Tensor. tf.compat.v1.Session uses an important function called run, which allows us to extract the tf.Tensor values as NumPy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239371e1-6c67-41d0-a9fe-174b3503fc87",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The Session graph is empty. Add operations to the graph before calling run().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m added \u001b[38;5;241m=\u001b[39m next_elem \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      9\u001b[0m sess \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mSession()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirst elem in batch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28mrepr\u001b[39m(\u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43madded\u001b[49m\u001b[43m)\u001b[49m)))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSecond elem in batch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mrepr\u001b[39m(sess\u001b[38;5;241m.\u001b[39mrun(added))))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m()  \u001b[38;5;66;03m# Newline\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py:967\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    964\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 967\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    969\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m    970\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py:1117\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1115\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempted to use a closed Session.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1117\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe Session graph is empty. Add operations to the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1118\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph before calling run().\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;66;03m# Create request.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m feed_dict_tensor \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The Session graph is empty. Add operations to the graph before calling run()."
     ]
    }
   ],
   "source": [
    "data = np.array([[1., 2.],\n",
    "       [3., 4.]])\n",
    "dataset = tf.compat.v1.data.Dataset.from_tensor_slices(data)\n",
    "dataset = dataset.batch(1)\n",
    "\n",
    "it = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "next_elem = it.get_next()\n",
    "added = next_elem + 1\n",
    "sess = tf.compat.v1.Session()\n",
    "\n",
    "print('First elem in batch: {}'.format(\n",
    "    repr(sess.run(added))))\n",
    "print('Second elem in batch: {}'.format(\n",
    "    repr(sess.run(added))))\n",
    "print()  # Newline\n",
    "try:\n",
    "    sess.run(added)  # OutOfRangeError\n",
    "except tf.errors.OutOfRangeError:\n",
    "    # New session\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        for i in range(2):\n",
    "            print(repr(sess.run(added)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf4c801-b4a7-4254-a985-a6cb291cf837",
   "metadata": {},
   "source": [
    "Similar to File I/O in Python, we can create a tf.compat.v1.Session with or without the with keyword. However, the with keyword lets us define all our computation within the scope of the tf.compat.v1.Session object, so we don’t have to manually close it to free its resources.\n",
    "\n",
    "In the example, the i^{th} time we call sess.run on added will return the i^{th} observation from the dataset. Since we used a + 1 transformation to obtain added from next_elem, each observation’s values are incremented by 1.\n",
    "\n",
    "Notice that if we call sess.run three consecutive times within the same tf.compat.v1.Session object scope, an OutOfRangeError is raised on the third call. This is because the dataset only contains two data observations, and we didn’t use the repeat function to increase the number of epochs we can iterate through.\n",
    "\n",
    "## Configured dataset\n",
    "\n",
    "The dataset used in the previous two examples was somewhat simplistic, and only intended to showcase the basics of the iteration process. For a more complex example, we’ll iterate through a dataset configured with shuffle, repeat, and batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c8dfc2-5630-467e-9301-17e461bb8351",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The Session graph is empty. Add operations to the graph before calling run().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m sess:\n\u001b[0;32m     16\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mElement \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m---> 18\u001b[0m       i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mrepr\u001b[39m(\u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_elem\u001b[49m\u001b[43m)\u001b[49m)))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py:967\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    964\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 967\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    969\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m    970\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py:1117\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1115\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempted to use a closed Session.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1117\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe Session graph is empty. Add operations to the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1118\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph before calling run().\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;66;03m# Create request.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m feed_dict_tensor \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The Session graph is empty. Add operations to the graph before calling run()."
     ]
    }
   ],
   "source": [
    "data = np.array([\n",
    "  [1., 2.],\n",
    "  [3., 4.],\n",
    "  [5., 6.],\n",
    "  [7., 8.],\n",
    "  [0., 9.],\n",
    "  [0., 0.]])\n",
    "\n",
    "dataset = tf.compat.v1.data.Dataset.from_tensor_slices(data)\n",
    "dataset = dataset.shuffle(6)\n",
    "dataset = dataset.repeat()\n",
    "dataset = dataset.batch(2)\n",
    "it = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "next_elem = it.get_next()\n",
    "with tf.compat.v1.Session() as sess:\n",
    "  for i in range(4):\n",
    "    print('Element {}: {}'.format(\n",
    "      i + 1, repr(sess.run(next_elem))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32f433f-4c01-470d-93e1-404402f33c07",
   "metadata": {},
   "source": [
    "The first thing to notice is that, despite dataset having only six data observations, we were able to iterate through eight observations because we used the repeat function. In fact, since we used repeat with its default argument setting, we could continuously iterate through the dataset without raising an OutOfRangeError.\n",
    "\n",
    "Since we set the batch size to 2 using batch, each iteration returned two data observations rather than 1. Furthermore, you’ll notice that the observations appear in a random order due to shuffle. However, we still saw all the data observations within the first epoch (i.e. first three iterations), because the shuffling occurs on a per-epoch basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d280e6-dc0f-4750-90a2-a8454bfe61c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
